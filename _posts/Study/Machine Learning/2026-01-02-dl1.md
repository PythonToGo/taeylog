---
title: Deep Learning I
description: Summary of Deep Learning
date: 2026-01-02
categories: [Study, Machine Learning]
author: PythonToGo
tags: [Machine Learning, Deep Learning, Neural Network, Activation Function, Loss Function ]
# pin: true
math: true
mermaid: true
comments: true
image: 
    type: pdf
    path: /assets/img/posts/study-ml/ch7-dl1.pdf
    page: 7
    alt: Koordinatensysteme und Transformation
---
{% include pdf-viewer.html %}
# Deep Learning I

## Background of Neural Network
### Limitation of Ligistic Regression and XOR-Dataset(non-linearly)
Logistic regression은 Linear decision boundary를 학습하기 때문에, XOR dataset과 같이 선형적으로 분리되지 않는 데이터를 처리하는데 실패한다. 여기서 우리는 비선형데이터를 위한 새로운 방법이 필요했고, 이것인 NN 이다.

### Basis Functions($\phi$)
비선형성을 처리하기 위해 입력 벡터 $x$를 선형 분리가 가능한 *새로운 공간으로 매핑*하는 basis function을 도입했다. 모델의 형태는 다음과 같다.

$$
f(x, w) = \sigma(w^T \phi(x)) 
$$
단, $w$에 대해서는 여전히 선형이다. 

<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1.pdf" data-page="4"></div>



이렇게, 과거에는 basis function 을 고정하고 Weight $w$만 학습했찌만, deep learning에서는 basis function 자체와 weight를 데이터로부터 동시게 학습한다. 이를 통해 1개의 hidden layer를 가진 **Feed-Forward Neural Network (FFNN)**모델이 구축된다.


## Deep Neural Network 구조
### Multi-layered Perceptron (MLP)
Hidden layer를 여러개 쌓아 만든 deep한 네트워크이다. 예를들어 3개의 층이 있다고 가정하자. 그럼 수식은 다음과 같다.
$$
f(x, W, b) = \sigma_2(W_2 \sigma_1 (W_1 \sigma_0 (W_0 x + b_0) + b1) + b2)
$$

### Activation Functions
여기서 우리는 **Activation Functions**가 등장하는데, 이것은 각 층의 출력에 비선형성을 부여하기 위해 추가된 개념이다. Softmax를 제외한 대부분은 element-wise로 적용된다. 종류는 *Sigmoid, tanh, ReLU*($max(0,x)$)*, Leaky ReLU* $max(0.1x, x)$*, ELU, Swish*$x \cdot \sigma(x)$ 등등 여러가지가 있다.

> 선형층만 여러 개 쌓으면 결국 하나의 선형변환으로 단순화 되기때문에, 복잡한 함수를 배우기 위해선 비선형 Activation Function이 필수적이다. 

{% include activation-functions-plot.html %}

이처럼, 충분히 많은 hidden unit과 적절한 activation function이 있다면, 1개의 hidden layer만으로도 닫힌 구간의 모든 연속 함수를 임의의 정밀도로 근사 가능하다. 이론적으로는 1개 층으로 모든 함수 표현이 가능하지만, 층을 더 깊게 쌓으면 동일한 표현력을 훨씬 적은 수의 파라미터로 달성 가능하다. 실제로도 학습 속도가 더 빠르고 generalization 성능이 더 좋다. 그리고 hierarchy of representations를 빠르게 학습할 수 있어 효율적이다. 


## Various Prediction Tasks and Loss Function
예측하려는 타겟에 따라 마지막 층의 activation function과 loss function이 달라진다.

| Prediction target | $p(y \lvert x)$ | Final layer | Loss function |
| --- | --- | --- | --- |
| Binary | Bernoulli | Sigmoid | Binary cross entropy |
| Discrete | Categorical | Softmax | Cross entropy |
| Continuous | Gaussian | Identity | Squared error |

### Binary Classification
- Data: $\set{x_n, y_n}^N_{n=1}$, where $y_n \in {0,1}$
- Activation in the final layer: **sigmoid**
$$
f(x, W) = \frac{1}{1 + exp(-a)}
$$
,where $a$ is the output of the last layer before activation (*logits*)

- Conditional distribution: Bernoulli
$$
p(y \lvert x) = Bernoulli(y \lvert f(x, W))
$$

- Loss function: binary cross entropy
$$
\begin{flalign}
E(W) = - \sum^N_{n=1} log \ p(y_n \lvert x_n) &&\\\nonumber
     = - \sum^N_{n=1} (y_n\ log f(x_n, W) + (1-y_n) \ log(1 - f(x_n, W)))
\end{flalign}
$$


### Multi-class classification
- Data: $\set{x_n, y_n\}^N_{n=1}$, where $y_n \in {0, 1}^K$ (one-hot notation)
- Activation in the final layer: **softmax**
$$
f_k (x, W) = \frac{exp(a_k)}{\sum^K_{j=1} exp(a_j)}
$$

- Conditional distribution: categorical
$$
p(y \lvert x) = Categorical(y \lvert f(x, W))
$$

- Loss function: categorical cross entropy
$$
\begin{flalign}
E(W) = - \sum^N_{n=1} log \ p(y_n \lvert x_n) &&\\\nonumber
     = - \sum^N_{n=1} \sum^K_{k=1} (y_{nk} \ log f_k(x_n, W))
\end{flalign}
$$


### Single-output regression
- Data: $\set{x_n, y_n}^N_{n=1}$, where $y_n \in \mathbb{R}$
- Activation in the final layer: **identity** - no activation
$$
f(x, W) = a
$$

- Conditional distribution: Gaussian
$$
p(y \lvert x) = \mathcal{N}(y \lvert f(x, W), 1 ) 
$$

-Loss function: squared error = a.k.a Gaussian cross-entropy
$$
\begin{flalign}
E(W) = - \sum^N_{n=1} log \ p(y_n \lvert x_n) &&\\\nonumber
     = - \sum^N_{n=1} (y_{n} - f(x_n, W))^2 + const
\end{flalign}
$$



지금까지는 정답이 있는 데이터를 사용하는 **supervised learning**을 다뤘지만 정답이 없는 데이터에서 패턴을 찾아내는 **unsupervised learning**분야도 있다.
### 주요 모델
- **Autoencoder**: 입력데이터를 압축했다가 다시 복원하는 구조
- **Variational Autoencoder (VAE)**: 데이터의 잠재적인 확률 분포를 학습하는 생성 모델
- **Generative Adversarial Networks (GAN)**: 두 네트워크가 서로 경쟁하며 정교한 데이터를 생성해내는 모델
- **Unsupervised representation learning**: 데이터의 특징을 스스로 학습하는 방식으로, *word embeddings* or *node embeddings* etc.

### How to choose loss function?
모델을 학습시킬때, 우리는 학습에 유용한  **gradient**를 제공할 수 있는 어떤 loss function라면, 자유롭게 선택 가능하다. 모델의 종류가 달라지는 것은 대개 이 loss를 무엇으로 선택하고 어떤 값을 비교하느냐의 차이에서 기인한다.

대표적으로

| Loss function | Character |
| --- | --- |
| Cross Entropy | 주로 Supervised classification 작업에 사용 |
| Mean Squared Error (MSE) | [ 예측값 - 실제값 ]의 제곱을 평균낸 것
| Mean Absolute Error (MAE) | 오차의 절대값을 평균 낸 것, Outliter가 존재하는 데이터에 유용하다. 하지만 Optimum과의 거리에 상관 없이 gradient가 일정하다 |
| Huber loss & LogCosh | MSE, MAE의 장점을 결합; 타겟과 가까운 거리에서 MSE처럼, 멀리떨어진곳에서는 MAE처럼 작동해서 수렴성능 + robustness 강화 |
| Wasserstein (earth mover's) distance & KL-divergence | 주로 연속적인 확률 분포 사이의 거리를 측정/비교 |


##  Minimizing the Loss
실제 환경에서 loss function $E(W)$는 대게 non-convex이므로, 최적화가 상당히 어렵다. 그리고 모든 Local minimum이 반드시  global minimum인 것은 아니며, 여러 개의 local minimum도 존재한다. 그리고 어떨때는, global minimum을 찾는 것이 불가능하거나, 유용하지 않을 수도 있다. 이럴때 사용하는 가장 기본적인 접근법이 **Gradient Descent**로, 현재 파라미터에서 negative gradient 방향으로 업데이트를 반복하는 것이다.  \\

업데이트 룰은 다음과 같다. 
$$
W^{(new)} = W^{(old)} - \tau \nabla_W E(W^{(old)})
$$

그렇다면, 이 Gradient를 계산하는 방법은 무엇인가? 결과적으론 총 4가지 방법이 있는데, 차례대로 생각해보자.
### How to calculate Gradient?
**1. By hand**: 수동으로 손으로,
**2. Numeric, formula**: $\frac{\partial E}{\partial w_{ijk}} \approx \frac{E(w_{ijk} + \epsilon) - E(w_{ijk})}{\epsilon} $ 공식을 사용한다. 하지만 모든 파라미터에 대해 독립적으로 계산을 하게 되면 연산의 복잡도가 거의 $O({\lvert W \rvert}^2)$가 되어 매우 비효울적이다.
**3. Symbolic differentiation**: 미분 공식을 자동화는 하지만, NN 같은 계층 구조에서는 항들을 재사용하기 힘들다. >> 비용 매우 커짐
그래서 마지막 방법이 바로 그 유명한 **Backpropagation**이다.
**4. Automatic differentiation (Backpropagation)**: 각 뉴런을 단 2번만 방문해 복잡도를 $O(\lvert W \rvert)$로 그래디언트를 계산하는 가장 효율적인 방식이다. 


<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="3"></div>


## Backpropagation 

Backpropagation은 전체 함수를 *모듈(modules)의 합성*으로 보고, chain rule을 적용한다.

### 기본절차
1. 함수를 모듈의 합성으로 정의한다.
2. 각 모듈의 local derivative를 기호적으로 도출한다.
3. Forward pass: 입력 $x$에 대한 출력을 계산하고, 중간 값들을 메모리에 저장(cache)한다.
4. Backward pass: 저장된 값을 사용해 로컬 미분을 계산하고, 이들을 곱해서 **global derivative**를 얻는다. 

<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="4"></div>

### Multivariate Chain Rule
연산 그래프에서 $x$로부터 $c$까지 경로가 여러개($a_1, ..., a_m$)일 경우, 모든 경로의 미분을 합산한다. 
$$
\frac{\partial c}{\partial x} = \sum^m_{i=1} \frac{\partial c}{\partial a_i} \frac{\partial a_i}{\partial x}
$$

<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="5"></div>


### Backpropagation Example
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="6"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="7"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="8"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="9"></div>

---

## 행렬 형태의 Chain Rule, Jacobian
고차원 데이터를 다룰 때는 Jacobian matrix를 사용해서 미분을 표현한다.

### Jacobian Function
$f: \mathbb{R}^n \implies \mathbb{R}^m$ 에 대해 $m \times n$ 행렬로 정의된다.

### Matrix form
$$
\nabla_x c = (\frac{\partial a}{\partial x})^T \nabla_a c,   \  ( \nabla_x c \in \mathbb{R}^n, \nabla_a c \in \mathbb{R}^m)
$$

실제로 구현햇을때, 거대한 Jacobian행렬을 직접 계산하지 않고, Jacobian vector product만 계산해서 메모리와 연산을 아낄 수 있다. 

<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="10"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="11"></div>

---

## Example of Affine Layer Backpropagation
선형 변환 을 Affine Layer 라고 한다. 이것의 예시를 보자.

| Form | Formula |
| --- | --- |
| Affine layer | $a = Wx + b$, $x \in \mathbb{R}^D, W \in \mathbb{R}^{H \times D}, b \in \mathbb{R}^H$ |
| Forward | Calculate $Wx + b$ |
| Backward - 1 | $\frac{\partial E}{\partial W} = (\frac{\partial E}{\partial a})^T x^T$ |
| Backward - 2 | $\frac{\partial E}{\partial x} = (\frac{\partial E}{\partial a}) W$ |
| Backward - 3 | $\frac{\partial E}{\partial b} = \frac{\partial E}{\partial a}$ |  


<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="12"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="13"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="14"></div>
<div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ml/ch7-dl1-bp.pdf" data-page="15"></div>

## 결론.
**Backpropagation**은 회사의 성과 보고 시스템과비슷함. 최종 이익(Loss 라고 볼수 있지)이 결정되면 사장부터 탑다운으로 말단 직원까지 거꾸로내려가면서 피드백 성과보고(Local derivative를 계산)를 하고 다음 분기의 업무 방향(Weight update)를 조정하는 것으로 비유 가능.

