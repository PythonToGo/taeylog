---
title: Probabilistic Inference - MLE, MAP, and Bayesian Estimation
description: MLE, MAP, and Bayesian Estimation
date: 2025-12-27
categories: [Study, Machine Learning]
tags: [Machine Learning, Probabilistic Inference, MLE, MAP, Bayesian Estimation]
pin: true
math: true
mermaid: true
comments: true
# image: 
#     path: 
#     lqip: 
#     alt: 
---

# Probabilistic Inference

## 1. Introduction & Model Assumptions

λ©μ : κ΄€μ°°ν• λ°μ΄ν„° $$D$$λ¥Ό λ°”νƒ•μΌλ΅ λ¨λΈ νλΌλ―Έν„° $$\theta$$λ¥Ό μ¶”λ΅ ν•κ±°λ‚, μƒλ΅μ΄ λ°μ΄ν„° $$x_{new}$$μ λ°μƒ ν™•λ¥ μ„ μμΈ΅ν•λ” κ²ƒμ΄λ‹¤.

### i.i.d. Assumptions

λ°μ΄ν„° λ¶„μ„μ„ μ„ν•΄ κ° κ΄€μ°°κ°’λ“¤μ΄ **independent and identically distributed** λμ–΄ μλ‹¤κ³  κ°€μ •ν•λ‹¤. (ν™•λ¥ μ΄λ‹κΉ)

- **Identical distribution**: λ¨λ“  λ°μ΄ν„°κ°€ λ™μΌν• νλΌλ―Έν„° $$\theta$$λ¥Ό κ°€μ§„λ‹¤
- **Independence**: κ° λ°μ΄ν„° ν¬μΈνΈλ” μ„λ΅ μν–¥μ„ μ£Όμ§€ μ•μΌλ―€λ΅ μ „μ²΄ ν™•λ¥ μ„ κ°λ³„ ν™•λ¥ μ κ³±μΌλ΅ λ‚νƒ€λ‚Ό μ μλ‹¤:
  $$
  p(D|\theta) = \prod_{i=1}^N p(x_i | \theta)
  $$

---

## 2. Maximum Likelihood Estimation (MLE)

MLEλ” κ΄€μ°°λ λ°μ΄ν„°μ λ°μƒ ν™•λ¥ μΈ **Likelihood** $$p(D|\theta)$$λ¥Ό μµλ€ν™”ν•λ” νλΌλ―Έν„° $$\theta$$λ¥Ό μ°Ύλ” κΈ°λ²•μ΄λ‹¤.

### Objective

$$
\theta_{MLE} = \arg\max_{\theta} p(D|\theta)
$$

### Log-likelihood

κ³„μ‚°μ νΈμμ„±κ³Ό μμΉμ  μ•μ •μ„±μ„ μ„ν•΄ Likelihood λ€μ‹ , **Log-likelihood** $$\log p(D|\theta)$$λ¥Ό μµλ€ν™”ν•λ‹¤. Logarithmμ€ Monotonic transformμ΄λ―€λ΅ μµλ“κ°’μ μ„μΉλ¥Ό λ³΄μ΅΄ν•κ³ , κ³±μ…μ„ λ§μ…μΌλ΅ λ³€ν™ν•΄μ„ λ” μ‰¬μ›€.

### Coin Flip μμ‹

λ™μ „ λμ§€κΈ°μ—μ„ Tμ™€ Hμ κ°μλ¥Ό κ°κ° $$|T|$$, $$|H|$$λΌ ν•  λ•:

$$
\theta_{MLE} = \frac{|T|}{|T|+|H|}
$$

### Gaussian μμ‹

ν‰κ·  $$\mu$$λ¥Ό μ¶”μ •ν•  λ•:

$$
\mu_{MLE} = \frac{1}{N} \sum_{i=1}^N x_i
$$

μ΄λ” λ°μ΄ν„°μ μ‚°μ  ν‰κ· κ³Ό κ°™λ‹¤. 


> π’΅ **μ¶”κ°€ μ„¤λ…**
> 
> MLEλ” λ°μ΄ν„°κ°€ μ μ„ λ• μ§κ΄€κ³Ό μ–΄κΈ‹λ‚λ” κ²°κ³Όλ¥Ό λ‚Ό μ μλ‹¤. μλ¥Ό λ“¤μ–΄ λ™μ „μ„ λ‘ λ² λμ Έ λ¨λ‘ Hκ°€ λ‚μ¤λ©΄, MLEλ” λ’·λ©΄μ΄ λ‚μ¬ ν™•λ¥  $$\theta$$λ¥Ό 0μΌλ΅ μ¶”μ •ν•μ§€λ§, μ΄λ” μ°λ¦¬μ μΌλ° μƒμ‹ Prior beliefμ™€ λ‹¤λ¥΄λ‹¤. κ·Έλμ„ μ—¬κΈ°μ„ (μ•„λμ— λ‚μ¬) MAPλ” λ°μ΄ν„°λ¥Ό κ΄€μ°°ν•κΈ° μ „μ—, μ°λ¦¬κ°€ κ°€μ§„ μ£Όκ΄€μ  λ―ΏμμΈ **Prior distribution** $$p(\theta)$$λ¥Ό λ¨Όμ € μν•™μ μΌλ΅ κ²°ν•©ν•λ‹¤. κ·Έλ¦¬κ³ , λ‹¨μν λ°μ΄ν„°μ κ°€λ¥μ„± $$p(D|\theta)$$μ„ λ†’μ΄λ” κ²ƒλ³΄λ‹¤λ”, **λ°μ΄ν„°κ°€ μ£Όμ–΄μ΅μ„ λ• νλΌλ―Έν„°κ°€ μ‹¤μ λ΅ μ΅΄μ¬ν•  ν™•λ¥ **μΈ **Posterior distribution** $$p(\theta | D)$$λ¥Ό κ³ λ ¤ν•λ‹¤. μ•„λ λ‚μ¤λ” MAPμ λ©μ μ€ Posterior distributionμ—μ„ κ°€μ¥ ν™•λ¥ μ΄ λ†’μ€ κ°’, μ¦‰ μµλΉκ°’(Mode)μ„ μ°Ύλ” κ²ƒμ΄λ‹¤. 


## Bayesian Inference

Bayesian κ΄€μ μ—μ„ νλΌλ―Έν„° $$\theta$$λ¥Ό κ³ μ •λ κ°’μ΄ μ•„λ‹, ν™•λ¥  λ¶„ν¬λ¥Ό κ°€μ§„ ν™•λ¥  λ³€μλ΅ μ·¨κΈ‰ν•λ‹¤.

### Prior Distribution $$p(\theta)$$

λ°μ΄ν„°λ¥Ό κ΄€μ°°ν•κΈ° μ „μ—, νλΌλ―Έν„°μ— λ€ν•΄ κ°€μ§€κ³  μλ” μ£Όκ΄€μ μΈ λ―Ώμμ„ μλ―Έν•λ‹¤.

### Posterior Distribution $$p(\theta|D)$$

λ°μ΄ν„°λ¥Ό κ΄€μ°°ν• ν›„ μ—…λ°μ΄νΈλ λ―Ώμμ΄λ‹¤. Bayes' Ruleμ— μν•΄ λ‹¤μκ³Ό κ°™μ΄ μ •μλλ‹¤:

$$
p(\theta | D) = \frac{p(D|\theta)p(\theta)}{p(D)}
$$

- **Likelihood** $$p(D|\theta)$$: λ°μ΄ν„°κ°€ μ£Όμ–΄μ΅μ„ λ• νλΌλ―Έν„°μ κ°€λ¥μ„±
- **Evidence** $$p(D)$$: Normalizing constantλ΅, posterior distributionμ ν•©μ΄ 1μ΄ λλ„λ΅ ν•λ‹¤

> β οΈ **μ¤‘μ”**: κ΄€κ³„μ‹: Posterior $$\propto$$ Likelihood $$\times$$ Prior



## Maximum a Posteriori (MAP) Estimation

MAPμ€ Posterior distributionμ„ μµλ€ν™”ν•λ” νλΌλ―Έν„° κ°’μ„ μ°Ύλ” λ°©μ‹μ΄λ‹¤.

### Objective

$$
\theta_{MAP} = \arg\max_{\theta} p(\theta | D) = \arg\max_{\theta} [\log p(D|\theta) + \log p(\theta)]
$$

### Priorμ μν–¥

λ°μ΄ν„°κ°€ μ μ„ λ• Priorμ μν–¥μ΄ κ°•ν•κ³ , MLEκ°€ κ°€μ§€λ” λ°μ΄ν„° λ¶€μ΅±μ— λ”°λ¥Έ νΈν–¥ λ¬Έμ λ¥Ό μ™„ν™”ν•΄μ¤€λ‹¤. λ°μ΄ν„°κ°€ λ§μ•„μ§μλ΅ Priorμ μν–¥λ ¥μ€ μ¤„μ–΄λ“¤κ³ , MAPμ€ MLEμ— μλ ΄ν•κ² λλ‹¤. 

### Coin Flipμ—μ„ Beta Priorλ¥Ό μ‚¬μ©ν–μ„ λ•

$$
\theta_{MAP} = \frac{|T| + a - 1}{|H| + |T| + a + b - 2}
$$

#### Beta Prior

Beta Priorλ” Bernoulli or Binomial distributionμ„ λ”°λ¥΄λ” λ°μ΄ν„°λ¥Ό λ¶„μ„ν•  λ• κ°€μ¥ λ„λ¦¬ μ‚¬μ©λλ” prior distributionμ΄λ‹¤.

**μν•™μ  μ •μ**:

$$
\text{Beta}(\theta | a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \theta^{a-1}(1 - \theta)^{b-1}
$$

- μ—¬κΈ°μ„ $$a, b > 0$$λ” λ¶„ν¬μ ν•νƒλ¥Ό κ²°μ •ν•λ” νλΌλ―Έν„°μ΄λ‹¤
- $$\Gamma(n)$$μ€ Gamma functionμΌλ΅, μμ—°μ $$n$$μ— λ€ν•΄ $$(n-1)!$$κ³Ό κ°™λ‹¤

**Conjugate Prior**: Beta distributionμ€ Bernoulli likelihoodμ— λ€ν•΄ conjugate priorμ΄λ‹¤.

- μ΄λ”, Priorκ°€ Beta λ¶„ν¬μΌ λ•, λ°μ΄ν„°λ¥Ό λ°μν• ν›„μ Posteriorλ„ λ°λ“μ‹ Beta λ¶„ν¬κ°€ λ¨μ„ μλ―Έν•λ‹¤
- μ΄ μ„±μ§μ— μν•΄ λ³µμ΅ν• μ λ¶„ κ³„μ‚° μ—†μ΄ λ‹¨μν νλΌλ―Έν„°λ¥Ό λ”ν•λ” κ²ƒλ§μΌλ΅ posterior distributionμ„ κµ¬ν•  μ μλ‹¤

**Pseudo-counts ν•΄μ„**: $$a$$μ™€ $$b$$λ” κ³Όκ±°μ— κ΄€μ°°ν• λ°μ΄ν„°μ νμλ΅ ν•΄μ„ν•λ‹¤. μ½”μΈ ν”λ¦½μ— λ‹¤μ‹ μ μ©ν•λ©΄:

- $$a$$: κ³Όκ±°μ— κ΄€μ°°ν• Tμ νμ
- $$b$$: κ³Όκ±°μ— κ΄€μ°°λ Hμ νμ
- λ§μ•½ $$a=1, b=1$$μ΄λΌλ©΄, μ΄λ” Uniform distributionμ΄ λμ–΄ μ•„λ¬΄λ° μ •λ³΄κ°€ μ—†λ” μƒνƒμ΄κ³ , μ΄λ• MAPμ€ MLEμ™€ λ™μΌν• κ²°κ³Όλ¥Ό λ‚νƒ€λ‚Έλ‹¤


### Gaussian μμ‹

μ •κ·λ¶„ν¬ Prior $$N(\mu| 0, \alpha^{-1})$$λ¥Ό κ°€μ§ λ•:

$$
\mu_{MAP} = \frac{1}{N+\alpha} \sum_{i=1}^N x_i
$$

μ΄λ” $$\alpha > 0$$μΌ λ•, $$\mu_{MLE}$$λ³΄λ‹¤ ν•­μƒ 0μ— λ” κ°€κΉμ΄ κ°’(**Shrinkage**)μ„ κ°€μ§„λ‹¤.



## Conjugate Priors

Priorμ™€ Posteriorκ°€ λ™μΌν• Familyμ λ¶„ν¬λ¥Ό λ”°λ¥Ό λ•, ν•΄λ‹Ή Priorλ¥Ό **Conjugate Prior**λΌκ³  ν•λ‹¤. μ΄ μ„±μ§μ„ ν†µν•΄ Posterior distributionμ ν•νƒλ¥Ό μ λ¶„ μ—†μ΄ pattern matchingμ„ ν†µν•΄ μ‰½κ² λ„μ¶ κ°€λ¥ν•λ‹¤.

### μ£Όμ” μ΅°ν•©

- Bernoulli Likelihood & Beta Prior β†’ Beta Posterior
- Binomial Likelihood & Beta Prior β†’ Beta Posterior
- Poisson Likelihood & Gamma Prior β†’ Gamma Posterior

### Posterior mean

**Posterior mean**μ€ λ€μ²΄λ΅ Prior meanκ³Ό MLE estimate μ‚¬μ΄μ Compromise(μ μ¶©μ•)μΌλ΅ λ‚νƒ€λ‚Έλ‹¤.



## Posterior Predictive Distribution

μƒλ΅μ΄ λ°μ΄ν„° $$x_{new}$$λ¥Ό μμΈ΅ν•  λ•, λ‹¨μν ν•λ‚μ μ  μ¶”μ •μΉ(MLE, MAP)λ¥Ό μ‚¬μ©ν•λ” κ²ƒμ΄ μ•„λ‹λΌ, Posterior distribution μ „μ²΄λ¥Ό κ³ λ ¤ν•λ” λ°©μ‹μ΄λ‹¤.

### Definition

$$
p(x_{new} | D, a, b) = \int p(x_{new} | \theta) p(\theta | D, a, b) d\theta
$$

### Marginalization

νλΌλ―Έν„° $$\theta$$μ— λ€ν•΄ μ λ¶„ν•΄μ„ $$\theta$$λ¥Ό μ κ±°ν•κ³  λ°μ΄ν„°μ— λ€ν• μ§μ ‘μ μΈ ν™•λ¥ μ„ κµ¬ν•λ” κ³Όμ •μ΄λ‹¤.

### Fully Bayesian Analysis

μ΄ λ°©μ‹μ€ νλΌλ―Έν„°μ— λ€ν• λ¶ν™•μ‹¤μ„±μ„ λ¨λ‘ κ³ λ ¤ν•κΈ° λ•λ¬Έμ— μ  μ¶”μ • λ°©μ‹(MLE, MAP)λ³΄λ‹¤ λ” ν¬κ΄„μ μΈ λ¶„μ„μ΄ κ°€λ¥ν•λ‹¤.


## κ²°λ΅ 

| κµ¬λ¶„ | Maximum Likelihood (MLE) | Maximum a Posteriori (MAP) | Fully Bayesian |
|------|-------------------------|---------------------------|----------------|
| λ©ν‘ | $$\max p(D|\theta)$$ | $$\max p(\theta|D)$$ | $$p(\theta|D)$$ μ „μ²΄ μ¶”μ • |
| κ²°κ³Ό | Point estimate | Point estimate | Full distribution |
| Prior μ‚¬μ© | μ—†μ (Uniformκ³Ό μ μ‚¬) | μ‚¬μ© | μ‚¬μ© |

Probabilistic Inferenceλ” λ°μ΄ν„°(Likelihood)λΌλ” μƒλ΅μ΄ μ¦κ±°μ™€ κΈ°μ΅΄μ μ§€μ‹(Prior) μ‚¬μ΄μ—μ„ κ· ν•μ„ λ§μ¶° λ‚κ°€λ” κ³Όμ •κ³Ό κ°™λ‹¤. λ°μ΄ν„°κ°€ μ“μΌμλ΅ μ°λ¦¬μ λ―Ώμ(Posterior)μ€ λ” μƒ¤ν”„ν•΄μ§€κ³ (peaky), μ¦‰ λ‹¤μ‹ λ§ν•΄ λ” ν™•μ‹ μ— μ°¬ μμΈ΅μ„ ν•  μ μλ‹¤.
 