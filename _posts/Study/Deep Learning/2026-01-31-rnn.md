---
title: RNN 
description: Summary of Bayesian Networks and Hidden Markov Models
date: 2026-01-31 10:00:00
categories: [Study, Deep Learning ]
author: PythonToGo
tags: [Deep Learning, RNN, Transformers ]
# pin: true
math: true
mermaid: true
comments: true
image: 
#     # type: pdf
    path: assets/img/posts/study-dl/rnn-architecture.png
# <div class="pdf-viewer-container" data-pdf="/assets/img/posts/study-ai/ch8.pdf" data-page="2"></div>
#     # page: 7
#     alt: 
---
{% include pdf-viewer.html %}

# RNN 

![RNN architecture](/assets/img/posts/study-dl/rnn-architecture.png)

## RNN 기본 아이디어

RNN 은 Sequence Data(time series, text, speech 등)을 처리하기 위해 설계됨. 

*현재* 시점의 output은 
- 현재 입력,
- 이전 시점의 hidden state

를 함께 사용해서 계산됨. 그래서 RNN 은 memory 를 가진다고 표현함.

## RNN equation

### Update hidden state

$$
h_t = \phi(W_x x_t + W_h h_{t-1} + b)
$$

- $$x_t$$ : 현재 시점 입력 
- $$h_{t-1}$$ : hidden state of previous time
- $$h_t$$ : hidden state of present
- $$ W_x, W_h$$: Weight matrix
- $$b$$ : bias
- $$\phi(\cdot)$$ : non linear function (ex, $$tanh$$ , $$ReLU$$ etc)
